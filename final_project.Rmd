---
title: "Project"
output: 
  flexdashboard::flex_dashboard:
    navbar:
      - { title: "Back", href:"https://donttt.github.io/ANLY503_Portfolio/",align: right}
    orientation: columns
    vertical_layout: fill
---


```{r setup, include=FALSE}
library(flexdashboard)
```
```{r}
library(scales)
library(jsonlite)
library(tidyverse)
library(sf)
library(spData)
library(maps)
library(ggmap)
library(leaflet)
library(leaflet.providers)
library(igraph)
library(networkD3)
library(dplyr)
library(tidyr)
library(wordcloud)
library(wordcloud2)
library(tm)
library(SnowballC)
library(RColorBrewer)
```

About
=======================================================================
The dataset is about the business that participated in Yelp app.

The data can be found at https://www.kaggle.com/yelp-dataset/yelp-dataset.

You can also download it from yelp website: https://www.yelp.com/dataset.\





Exploratory
=======================================================================
```{r,include = FALSE}
myJSON <- . %>%
  file %>%
  stream_in()
business <- myJSON("data/yelp_academic_dataset_business.json")
```

```{r,include=FALSE}
state_count <- business %>%
  group_by(state) %>%
  dplyr::summarise(count = n()) %>%
  arrange(desc(count))
```


Here is a brief view of what the Business data. On the left is the distribution of businesses participate with Yelp. Since the data set is very large, I will choose PA part for Geographical and Network. 
On the right sight is pie charts for rating stars, which is qualitative data. Since 10 levels is too much in the view, I choose to round it to 5 levels. And I will compare these two level in Geographical part.

Column {data-width=650}
-----------------------------------------------------------------------

### Chart A

```{r}
num_by_state <- state_count %>% 
  top_n(10,count) %>%
  ggplot(aes(x=reorder(state,-count),y = count)) +
  geom_bar(stat = "identity",aes(fill=state))+
  xlab("state")+
  ylab("Number of Business")+
  ggtitle("Number of Business by State")+
  theme_classic()
num_by_state
```

Column {data-width=350}
-----------------------------------------------------------------------

### Chart B

```{r}
PA <- subset(business, state == "PA")
rating <- PA %>%
  group_by(stars) %>%
  dplyr::summarise(count = n())%>%
  arrange(desc(stars))

rating$stars <- as.factor(rating$stars)
blank_theme <- theme_minimal()+
  theme(
  axis.title.x = element_blank(),
  axis.title.y = element_blank(),
  panel.border = element_blank(),
  panel.grid=element_blank(),
  axis.ticks = element_blank(),
  plot.title=element_text(size=14, face="bold")
  )

rating %>%
  ggplot(aes(x = "",y = count,fill = stars))+
  geom_bar(width = .8,stat = "identity")+
  coord_polar("y", start=0)+
  scale_fill_brewer("Stars")+
  blank_theme +
  theme(axis.text.x=element_blank(),axis.text.y=element_blank())+
  geom_text(aes(y = count/3 + c(0, cumsum(count)[-length(count)]), 
            label = percent(count/sum(count))), size=3)+
  ggtitle("Pie with 10 levels of stars")
```

### Chart C

```{r}
rating <- PA
rating$stars <- round(rating$stars)
rating <- rating%>%
  group_by(stars) %>%
  dplyr::summarise(count = n())%>%
  arrange(desc(stars))
rating$stars <- as.factor(rating$stars)


rating %>%
  ggplot(aes(x = "",y = count,fill = stars))+
  geom_bar(width = .8,stat = "identity")+
  coord_polar("y", start=0)+
  scale_fill_brewer("Stars")+
  blank_theme +
  theme(axis.text.x=element_blank(),axis.text.y=element_blank())+
  geom_text(aes(y = count/3 + c(0, cumsum(count)[-length(count)]), 
            label = percent(count/sum(count))), size=3)+
  ggtitle("Pie with 5 levels of stars")
```

Geographical
=======================================================================
There are 4 figures in this parts. They are plots of business distribution at Pittsburgh. On the top left side is Business distribution by stars with 5 levels. In order to find there distribution difference, I plotted their distribution center at the bottom. The circle size is related to the business number. From the graph we can see that business with higher stars are tend to located to the east side of the city, while lower stars business tend to locate to the west side. The 10 level stars business distribution plot also confirms the finding. Therefore, if people would like to having food or shopping at Pittsburgh, it is better to go to the east part of the city.

Row
-------------------------------------
    
### Chart 1 Business Distribution By Stars
    
```{r,include=FALSE}
city_b <- st_read("data/Pittsburgh_City_Boundary-shp/City_Boundary.shp")
```

```{r}
PI <- subset(business, city == "Pittsburgh")
PI <- subset(PI, latitude <43) ## drop wrong data

PI$stars <- round(PI$stars)
PI$stars <- as.factor(PI$stars)

pal <- colorFactor(
  palette = c('red', 'blue', 'green', 'purple', 'orange'),
  domain = PI$stars
)

#PI <- subset(PI, latitude <40.50097 & latitude>40.36161 & longitude %in% c(-80.09534:-79.86577))

leaflet(PI) %>%
  addTiles() %>% 
  addCircleMarkers(~longitude, ~latitude, radius=1,color = ~pal(stars))%>%
  setView(lng =-79.98757 , lat = 40.44388, zoom = 10)%>%
  addPolygons(data = city_b,fillOpacity = 0.2,color = grey) %>%
  leaflet::addLegend("bottomleft", pal =pal,values = PI$stars)
```
 
### Chart 2 Business Distribution By Stars
    
```{r}
center <- PI%>%
  group_by(stars)%>%
  dplyr::summarise(mean_lon =mean(longitude),mean_lat = mean(latitude),count = n())

leaflet(center) %>%
  addTiles() %>% 
  addCircleMarkers(~mean_lon, ~mean_lat, radius=~sqrt(count),color = ~pal(stars))%>%
  setView(lng =-79.98757 , lat = 40.44388, zoom = 13)%>%
  addPolygons(data = city_b,fillOpacity = 0.2,color = grey) %>%
  leaflet::addLegend("bottomleft", pal =pal,values = center$stars)
``` 

Row
-------------------------------------
    
### Chart 3 Business Distribution By Stars
    
```{r}
PI <- subset(business, city == "Pittsburgh")
PI <- subset(PI, latitude <43) ## drop wrong data
PI$stars <- as.factor(PI$stars)

pal <- colorFactor(
  palette = c('red', 'blue', 'green', 'purple', 'orange',"#264653","#2a9d8f","#e9c46a","#f4a261","#e76f51"),
  domain = PI$stars
)

#PI <- subset(PI, latitude <40.50097 & latitude>40.36161 & longitude %in% c(-80.09534:-79.86577))

leaflet(PI) %>%
  addTiles() %>% 
  addCircleMarkers(~longitude, ~latitude, radius=1,color = ~pal(stars))%>%
  setView(lng =-79.98757 , lat = 40.44388, zoom = 10)%>%
  addPolygons(data = city_b,fillOpacity = 0.2,color = grey) %>%
  leaflet::addLegend("bottomleft", pal =pal,values = PI$stars)
```
    
### Chart 4 Business Distribution By Stars

```{r}
center <- PI%>%
  group_by(stars)%>%
  dplyr::summarise(mean_lon =mean(longitude),mean_lat = mean(latitude),count = n())

leaflet(center) %>%
  addTiles() %>% 
  addCircleMarkers(~mean_lon, ~mean_lat, radius=~sqrt(count),color = ~pal(stars))%>%
  setView(lng =-79.98757 , lat = 40.44388, zoom = 14)%>%
  addPolygons(data = city_b,fillOpacity = 0.1,color = grey) %>%
  leaflet::addLegend("bottomleft", pal =pal,values = center$stars)
```






Network

The Network is a study about the American Food business. There are two kinds of American Food business: Traditional and New. The network shows what business categories are related to the two American Food styles. There are also many overlaps between these two styles.

=======================================================================
### Chart 1
    
```{r,include=FALSE}
PA <- subset(business, city == "Pittsburgh")
category <- PA['categories']
cate_sep <- category %>% separate(categories,paste0("col",c(1:14)),sep = ",",remove = T)
cate_pivot <- cate_sep %>% pivot_longer(!col1) %>% drop_na()
connect <- cate_pivot[-2]
colnames(connect)[2] <- "col2"

connect <- cbind(connect,value = 1)

connect <- connect %>% 
  group_by(col1,col2) %>%
  dplyr::summarise(weight = n())
American_connect <- connect %>% filter(col1 == "American (New)"|col2 == "American (New)"|col1 == "American (Traditional)" | col2 == "American (Traditional)")
```

```{r}
nodes <- data.frame(name = unique(c(American_connect$col1, American_connect$col2)))

nodes$group <- nodes$name %in% American_connect$col1

links <- data.frame(source = match(American_connect$col1,nodes$name)-1,
                    target = match(American_connect$col2,nodes$name)-1,
                    count = American_connect$weight)
my_color <- 'd3.scaleOrdinal() .domain(["source", "target"]).range(["#FF6900","#ad92de"])'
forceNetwork(Links = links, Nodes = nodes, Source = "source",
             Target = "target",NodeID = "name",Group = "group",
             Value = "count",
             opacity = 2, opacityNoHover = 1,zoom = TRUE,
             colourScale =my_color)
```

Time Series
=======================================================================

The time series is the ratings over time of the mostly rated restaurant among all these business. This business has an average of 4 stars rating. 
The moving average line shows that this restaurant always has a very high level of rating.


Column 
-------------------------------------
### Chart 1

```{r,include=FALSE}
best_business <- business%>%
  arrange(.,-review_count)%>%
  head(1)%>%
  select(business_id)
best_business$business_id
```

```{r,eval=FALSE}
##Original file is too large, extract useful information and save to csv for future.
review <- myJSON("yelp_academic_dataset_review.json")

best_review <- review[which(review$business_id=="RESDUcs7fIiihp38-d6_6g"),]
write.csv(best_review,"best_review.csv",row.names = FALSE)

pitts_business <- business[which(business$city=="Pittsburgh"),] %>% select(business_id)
pitts_review <- review[which(review$business_id %in% pitts_business$business_id),]
write.csv(pitts_review,"pitts_review.csv",row.names = FALSE)
```


```{r,include=FALSE}
library(zoo)
best_review <- read_csv("data/best_review.csv",locale = locale(encoding = 'UTF-8'))
#best_review <- read.csv("data/best_review.csv",encoding = "UTF-8")
best_review <- best_review[order(best_review$date),]
```


```{r}
ma <- rollmean(best_review$stars,500)
ma_date <- best_review$date


best_review[500:10417,]%>% 
  ggplot(aes(x=date,y = stars))+
  geom_line(aes(color = "time series"))+
  geom_line(aes(y = ma,x=ma_date[500:10417],color = "moving average"))+
  xlab("date")+
  ggtitle("Time Series for the stars of the most rated restaurant")+
  theme_light()
  
```




Text
=======================================================================

The word cloud on the left is from the comment of people who gave 5 stars for the restaurant.(Please refresh page to get the wordcloud)
On the right side is the barchart of the word frequency.
From the graph we can see that people are extremely satisfied with their food and their buffet style.
(Since the text file is too large and it took more than 1 hour to read in. I saved useful information to csv for plotting. The code can be found in the rmarkdown.)


```{r,eval=FALSE}
myJSON <- . %>%
  file %>%
  stream_in()
#xa <- myJSON("data/xaa.json")
xb <- myJSON("data/xab.json")
xc <- myJSON("data/xac.json")
#xd <- myJSON("data/xad.json")

## there is not data of business "RESDUcs7fIiihp38-d6_6g" in x1,x4
#x1 <- xa[which(xa$business_id=="RESDUcs7fIiihp38-d6_6g"),]
x2 <- xb[which(xb$business_id=="RESDUcs7fIiihp38-d6_6g"),]
x3 <- xc[which(xc$business_id=="RESDUcs7fIiihp38-d6_6g"),]
#x4 <- xd[which(xd$business_id=="RESDUcs7fIiihp38-d6_6g"),]
best_review2 <- rbind(x2,x3)
write.csv(best_review2,"data/best_review2.csv")
```



```{r,include=FALSE}
best_review <- read_csv("data/best_review2.csv")
```



```{r,include=FALSE}
review5 <- best_review[which(best_review$stars==5),]
review1 <- best_review[which(best_review$stars==1),]
review5<- review5$text
review1<- review1$text
r5 <- Corpus(VectorSource(review5))
r1 <- Corpus(VectorSource(review1))
```


```{r,include=FALSE}
r5 <- r5 %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace)
r5 <- tm_map(r5, content_transformer(tolower))
r5 <- tm_map(r5, removeWords, stopwords("english"))

dtm5 <- TermDocumentMatrix(r5)
matrix5 <- as.matrix(dtm5)
words5 <- sort(rowSums(matrix5),decreasing=TRUE) 
df5 <- data.frame(word = names(words5),freq=words5)
set.seed(1234) # for reproducibility 
#wordcloud(words = df$word, freq = df$freq, min.freq = 1,max.words=200,random.order=FALSE, rot.per=0.35,colors=brewer.pal(8, "Dark2"))

w1 <- wordcloud2(df5[1:80,],size=1)
```
Column 
-------------------------------------
### Chart 1 Please refresh page to get the wordcloud

```{r}
w1
```


Column 
-------------------------------------
### Chart 2

```{r}
df5[1:10,] %>% ggplot(aes(x=reorder(word,freq),y = freq))+
  geom_bar(stat = "identity",fill ="orange")+
  coord_flip()+
  labs(x = "word",y = "frequency",title = "Top 10 word frequency in 5 stars comment")+
  theme_bw()
```

